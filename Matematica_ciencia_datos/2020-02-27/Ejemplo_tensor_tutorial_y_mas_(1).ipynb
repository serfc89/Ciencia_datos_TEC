{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "Ejemplo_tensor_tutorial_y_mas.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "QOXhJt2-lgTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKyR17culgTZ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "What is PyTorch?\n",
        "================\n",
        "\n",
        "It’s a Python-based scientific computing package targeted at two sets of\n",
        "audiences:\n",
        "\n",
        "-  A replacement for NumPy to use the power of GPUs\n",
        "-  a deep learning research platform that provides maximum flexibility\n",
        "   and speed\n",
        "\n",
        "Getting Started\n",
        "---------------\n",
        "\n",
        "Tensors\n",
        "^^^^^^^\n",
        "\n",
        "Tensors are similar to NumPy’s ndarrays, with the addition being that\n",
        "Tensors can also be used on a GPU to accelerate computing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "pJXj6hf0lgTd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbe815cJlgTk",
        "colab_type": "text"
      },
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>An uninitialized matrix is declared,\n",
        "    but does not contain definite known\n",
        "    values before it is used. When an\n",
        "    uninitialized matrix is created,\n",
        "    whatever values were in the allocated\n",
        "    memory at the time will appear as the initial values.</p></div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojtyv1tflgTm",
        "colab_type": "text"
      },
      "source": [
        "Construct a 5x3 matrix, uninitialized:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "WePgIxEZlgTp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "db224777-0b96-47c4-e0db-913cb003ef54"
      },
      "source": [
        "x = torch.empty(5, 3)\n",
        "print(x)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[8.7603e-36, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 2.8026e-45],\n",
            "        [0.0000e+00, 1.1210e-44, 0.0000e+00],\n",
            "        [1.4013e-45, 0.0000e+00, 0.0000e+00]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5g9kdRalgTw",
        "colab_type": "text"
      },
      "source": [
        "Construct a randomly initialized matrix:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "kaeJ9FrXlgTy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "78b2db03-d4fd-4c9b-b0c7-aa0f325790ac"
      },
      "source": [
        "x = torch.rand(5, 3)\n",
        "print(x)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.3635, 0.1017, 0.9504],\n",
            "        [0.1565, 0.2354, 0.5619],\n",
            "        [0.7182, 0.3226, 0.3734],\n",
            "        [0.8418, 0.9458, 0.9143],\n",
            "        [0.2763, 0.4324, 0.9476]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xS94wEu9lgT5",
        "colab_type": "text"
      },
      "source": [
        "Construct a matrix filled zeros and of dtype long:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "OjKaCRTVlgT7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "01fe21b2-c3a6-4530-9d26-9fcc29fd83bc"
      },
      "source": [
        "x = torch.zeros(5, 3, dtype=torch.long)\n",
        "print(x)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbFOZq-AlgUD",
        "colab_type": "text"
      },
      "source": [
        "Construct a tensor directly from data:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "NzcuVjxblgUF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "d174aaa1-4583-4dd0-e6ce-bb17546e99c8"
      },
      "source": [
        "x = torch.tensor([5.5, 3])\n",
        "print(x)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([5.5000, 3.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPyp7pNjlgUO",
        "colab_type": "text"
      },
      "source": [
        "or create a tensor based on an existing tensor. These methods\n",
        "will reuse properties of the input tensor, e.g. dtype, unless\n",
        "new values are provided by user\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "4fyYV4EslgUQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "6f535596-da1c-4b53-a8f8-500dd10d8442"
      },
      "source": [
        "x = x.new_ones(5, 3, dtype=torch.double)      # new_* methods take in sizes\n",
        "print(x)\n",
        "\n",
        "x = torch.randn_like(x, dtype=torch.float)    # override dtype!\n",
        "print(x)                                      # result has the same size"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]], dtype=torch.float64)\n",
            "tensor([[-1.4960,  0.1864, -0.8546],\n",
            "        [-1.0108,  0.8689,  0.1743],\n",
            "        [ 1.2192, -0.6937,  0.2066],\n",
            "        [ 0.6286,  0.5729, -0.9923],\n",
            "        [ 0.8891,  0.6449,  2.3466]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqirONQFlgUW",
        "colab_type": "text"
      },
      "source": [
        "Get its size:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "7bfJ7odilgUa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "1dccfeb7-3424-4406-e19d-ce31accefec8"
      },
      "source": [
        "print(x.size())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwqOyQhPlgUj",
        "colab_type": "text"
      },
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>``torch.Size`` is in fact a tuple, so it supports all tuple operations.</p></div>\n",
        "\n",
        "Operations\n",
        "^^^^^^^^^^\n",
        "There are multiple syntaxes for operations. In the following\n",
        "example, we will take a look at the addition operation.\n",
        "\n",
        "Addition: syntax 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "0qT68ZyMlgUl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "3eb4ab33-b052-4b35-b24c-011b74323f7c"
      },
      "source": [
        "y = torch.rand(5, 3)\n",
        "print(x + y)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.6339,  0.7942, -0.7402],\n",
            "        [-0.2414,  1.8494,  1.1240],\n",
            "        [ 2.1132,  0.1695,  1.1596],\n",
            "        [ 1.5395,  0.9220, -0.8208],\n",
            "        [ 0.9461,  1.4256,  2.4228]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVE8kDjFlgUs",
        "colab_type": "text"
      },
      "source": [
        "Addition: syntax 2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "KAhfay53lgUv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "77de6a16-9809-4201-f947-4d0524802f59"
      },
      "source": [
        "print(torch.add(x, y))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.6339,  0.7942, -0.7402],\n",
            "        [-0.2414,  1.8494,  1.1240],\n",
            "        [ 2.1132,  0.1695,  1.1596],\n",
            "        [ 1.5395,  0.9220, -0.8208],\n",
            "        [ 0.9461,  1.4256,  2.4228]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOdsZsKulgU2",
        "colab_type": "text"
      },
      "source": [
        "Addition: providing an output tensor as argument\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "Y4zNur2ClgU4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "bd7660fa-27d9-4e0f-d179-ac320ce69d3e"
      },
      "source": [
        "result = torch.empty(5, 3)\n",
        "torch.add(x, y, out=result)\n",
        "print(result)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.6339,  0.7942, -0.7402],\n",
            "        [-0.2414,  1.8494,  1.1240],\n",
            "        [ 2.1132,  0.1695,  1.1596],\n",
            "        [ 1.5395,  0.9220, -0.8208],\n",
            "        [ 0.9461,  1.4256,  2.4228]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxDMAGMelgVA",
        "colab_type": "text"
      },
      "source": [
        "Addition: in-place\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "j3q78RfFlgVD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "d2359308-5b2d-4c09-97ed-9265c15a6889"
      },
      "source": [
        "# adds x to y\n",
        "y.add_(x)\n",
        "print(y)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.6339,  0.7942, -0.7402],\n",
            "        [-0.2414,  1.8494,  1.1240],\n",
            "        [ 2.1132,  0.1695,  1.1596],\n",
            "        [ 1.5395,  0.9220, -0.8208],\n",
            "        [ 0.9461,  1.4256,  2.4228]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAbtZh8_lgVL",
        "colab_type": "text"
      },
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>Any operation that mutates a tensor in-place is post-fixed with an ``_``.\n",
        "    For example: ``x.copy_(y)``, ``x.t_()``, will change ``x``.</p></div>\n",
        "\n",
        "You can use standard NumPy-like indexing with all bells and whistles!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "GksKpxB0lgVN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "3b3c93ee-6cc0-4f47-a608-c1e6c7037738"
      },
      "source": [
        "print(x[:, 1])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 0.1864,  0.8689, -0.6937,  0.5729,  0.6449])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypDvGDiflgVX",
        "colab_type": "text"
      },
      "source": [
        "Resizing: If you want to resize/reshape tensor, you can use ``torch.view``:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "95vDNQyzlgVY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "3693c70f-ebbe-4bd5-b299-ef41b87511e9"
      },
      "source": [
        "x = torch.randn(4, 4)\n",
        "y = x.view(16)\n",
        "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
        "print(x.size(), y.size(), z.size())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqH3MYBmlgVf",
        "colab_type": "text"
      },
      "source": [
        "If you have a one element tensor, use ``.item()`` to get the value as a\n",
        "Python number\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "CDHjgQxulgVm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "6e80102f-fa76-4b73-ece6-859abbf60185"
      },
      "source": [
        "x = torch.randn(1)\n",
        "print(x)\n",
        "print(x.item())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2.0322])\n",
            "2.0322117805480957\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pVKBuyblgVr",
        "colab_type": "text"
      },
      "source": [
        "**Read later:**\n",
        "\n",
        "\n",
        "  100+ Tensor operations, including transposing, indexing, slicing,\n",
        "  mathematical operations, linear algebra, random numbers, etc.,\n",
        "  are described\n",
        "  `here <https://pytorch.org/docs/torch>`_.\n",
        "\n",
        "NumPy Bridge\n",
        "------------\n",
        "\n",
        "Converting a Torch Tensor to a NumPy array and vice versa is a breeze.\n",
        "\n",
        "The Torch Tensor and NumPy array will share their underlying memory\n",
        "locations (if the Torch Tensor is on CPU), and changing one will change\n",
        "the other.\n",
        "\n",
        "Converting a Torch Tensor to a NumPy Array\n",
        "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "NHYAaLb7lgVt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "29c6c5e9-f444-413a-bb84-2e2517df4d82"
      },
      "source": [
        "a = torch.ones(5)\n",
        "print(a)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "zb6UJ1PplgVz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "7faddc8b-ca00-438f-bd1e-e1313795330b"
      },
      "source": [
        "b = a.numpy()\n",
        "print(b)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 1. 1. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFWmrgkUlgV5",
        "colab_type": "text"
      },
      "source": [
        "See how the numpy array changed in value.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "-HTpHTZ7lgV6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "eccb241c-f76a-4955-fe8a-f97dcc039b0d"
      },
      "source": [
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkIY4Kv2lgV_",
        "colab_type": "text"
      },
      "source": [
        "Converting NumPy Array to Torch Tensor\n",
        "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "See how changing the np array changed the Torch Tensor automatically\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "n3JWURzBlgWB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "292d8e41-3f0e-4548-a94d-1b3d3adb5964"
      },
      "source": [
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "np.add(a, 1, out=a)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCOJ1Ganl2sB",
        "colab_type": "text"
      },
      "source": [
        "# Operaciones con vectores\n",
        "\n",
        "**Definición**: El producto del vector $x$ por el escalar $\\alpha$ es un vector\n",
        "$$$$\n",
        "$$\n",
        "\\alpha x = \\alpha \\begin{bmatrix}x_1 \\\\ x_2 \\\\ ... \\\\ x_n\\end{bmatrix} = \n",
        "            \\begin{bmatrix} \\alpha x_1 \\\\ \\alpha x_2 \\\\ ... \\\\ \\alpha x_n\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "$$$$\n",
        "\n",
        "Los vectores $a$ and $b$ para los que existe un escalar $\\alpha$ que cumple $a = \\alpha b$ or $b = \\alpha a$, son llamados $\\mathbf{vectores~colineales}$. Estos vectores, como su nombre sugiere, se encuentran sobre líneas paralelas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19CKPId2mQH3",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "## Otro ejemplo de cómo escribir fórmulas\n",
        "\n",
        "\n",
        "*   $g(t)=\\sqrt{u(t)}$. Con una entrada dada por $\\alpha u_{1}(t)+\\beta u_{2}(t)$, se tiene que: \n",
        "\n",
        "$L\\left\\{ \\alpha f_{1}\\left(x\\right)+\\beta f_{2}\\left(x\\right)\\right\\}$ $=$ $\\alpha L\\left\\{ f_{1}(x)\\right\\} +\\beta L\\left\\{ f_{2}(x)\\right\\}$\n",
        "\n",
        "\n",
        "$\\sqrt{\\left(\\alpha u_{1}(t)+\\beta u_{2}(t)\\right)}$ $=?$ $ \\alpha\\sqrt{u_{1}(t)}+\\beta\\sqrt{u_{2}(t)}$\n",
        "\n",
        "\n",
        "por lo tanto el sistema no es lineal. \n",
        "\n"
      ]
    }
  ]
}