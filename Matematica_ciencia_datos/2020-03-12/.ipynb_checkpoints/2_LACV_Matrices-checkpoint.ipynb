{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LACV_Matrices.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MztdSyMHLcbu",
        "colab_type": "text"
      },
      "source": [
        "# Matemática para Ciencia de los Datos - Matrices\n",
        "\n",
        "-Profesor: Luis Alexánder Calvo Valverde.\n",
        "\n",
        "- Documento base: Saúl Calderón, Žiga Emeršič, Ángel García, Blaž Meden, Felipe Meza, Martín Solís, Juan Esquivel, Mauro Méndez, Manuel Zumbado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sPD8sqQXo3_P"
      },
      "source": [
        "# Matrices\n",
        "El álgebra lineal facilita la expresión de múltiples operaciones, como por ejemplo las operaciones en ecuaciones lineales, como el siguiente sistema:\n",
        "\n",
        "\\begin{array}{c}\n",
        "4x_{1}-5x_{2}=-13\\\\\n",
        "-2x_{1}+3x_{2}=9\n",
        "\\end{array}\n",
        "\n",
        "\n",
        "El sistema de ecuaciones anterior tiene igual número de ecuaciones y variables.\n",
        "\n",
        "En notación matricial, el sistema de ecuaciones anterior se expresa de la siguiente forma: \n",
        "\n",
        "\\begin{equation}\n",
        "A\\,\\vec{x}=b\n",
        "\\end{equation}\n",
        "\n",
        "con \n",
        "\n",
        "\\begin{equation}\n",
        "A=\\begin{bmatrix}4 & -5\\\\\n",
        "-2 & 3\n",
        "\\end{bmatrix},\\qquad b=\\begin{bmatrix}-13\\\\\n",
        "9\n",
        "\\end{bmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "En el material del curso se utilizará la siguiente notación:\n",
        "\n",
        "\n",
        "- Con $A\\in\\mathbb{R}^{m\\times n}$ se define una matriz con $m$ filas\n",
        "y $n$ columnas, donde en este caso todas las entradas de $A$ son\n",
        "números reales.\n",
        "\n",
        "- Con $\\vec{x}\\in\\mathbb{R}^{n\\times1}=\\mathbb{R}^{n}$ se denota un\n",
        "vector con $n$ entradas. Por convención, un vector $n$ dimensional\n",
        "se define como una matriz de $n$ filas y $1$ columna, conocido como\n",
        "el **vector columna**: \n",
        "\n",
        "\\begin{equation}\n",
        "\\overrightarrow{x}=\\begin{bmatrix}x_{1}\\\\\n",
        "x_{2}\\\\\n",
        "\\vdots\\\\\n",
        "x_{n}\n",
        "\\end{bmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "y el elemento $i$ del vector se denota como $x_{i}$. Un vector fila se define entonces de la siguiente forma (usando la definición de la transpuesta): \n",
        "\n",
        "\\begin{equation}\n",
        "\\overrightarrow{x}^{T}=\\begin{bmatrix}x_{1} & x_{2} & \\ldots & x_{n}\\end{bmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "- Para denotar los elementos de una matriz se usa la notación $a_{i,j}$\n",
        "($A_{ij}$, $A_{i,j}$,$A\\left(i,j\\right)$, etc) para denotar una\n",
        "entrada de la matriz $A$ en la fila $i$ y la columna $j$:\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "A=\\begin{bmatrix}a_{1,1} & a_{1,2} & \\ldots & a_{1,n}\\\\\n",
        "a_{2,1} & a_{2,2} & \\ldots & a_{2,n}\\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
        "a_{m,1} & a_{m,2} &  & a_{m,n}\n",
        "\\end{bmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "y se define la columna $j$ de la matriz $A$ con $a_{j}$ o $A_{:,j}$,\n",
        "de modo que la matriz $A$ está definida en términos de vectores columna\n",
        "por:\n",
        "\n",
        "\\begin{equation}\n",
        "A=\\begin{bmatrix}| & | & \\ldots & |\\\\\n",
        "\\overrightarrow{a}_{:,1} & \\overrightarrow{a}_{:,2} & \\ldots & \\overrightarrow{a}_{:,n}\\\\\n",
        "| & | & \\ldots & |\n",
        "\\end{bmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "y se define la fila $i$ de tal matriz como $\\vec{a}_{i,:}^{T}$ o $A_{i,:}$, por lo que en términos de tales vectores fila la matriz $A$ se expresa como:\n",
        "\n",
        "\\begin{equation}\n",
        "A=\\begin{bmatrix}- & \\vec{a}_{1,:}^{T} & -\\\\\n",
        "- & \\vec{a}_{2,:}^{T} & -\\\\\n",
        " & \\vdots\\\\\n",
        "- & \\vec{a}_{m,:}^{T} & -\n",
        "\\end{bmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "**Nota:** - $A$ es una matriz cuadrada cuando $A\\in\\mathbb{R}^{n\\times n}$, igual cantidad de filas que de columnas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5-ubyuTP4hF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Si no tiene instalado pytorch hay que hacerlo\n",
        "!pip install torch\n",
        "\n",
        "###############################################################################\n",
        "import torch as torch\n",
        "import math \n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib import cm\n",
        "###############################################################################\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUmZ85_SPekl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A = torch.tensor([ [1. , 2. , 3. ], [4. , 5. , 6. ] , [7. , 8. , 9.]])\n",
        "print( A )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tS_OtJ0JGC4I"
      },
      "source": [
        "## La matriz identidad y diagonal\n",
        "\n",
        "La matriz identidad, definida como una matriz cuadrada $I\\in\\mathbb{R}^{n\\times n}$ y está formada por una diagonal de unos, y el resto de entradas de la matriz está en cero: \n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "I_{i,j}=\\begin{cases}\n",
        "1 & i=j\\\\\n",
        "0 & i\\neq j\n",
        "\\end{cases}\n",
        "\\end{equation}\n",
        "\n",
        "y es el neutro de la multiplicación matricial, por lo que para toda $A\\in\\mathbb{R}^{m\\times n}$ se tiene que: \n",
        "\n",
        "\\begin{equation}\n",
        "A\\,I=A\n",
        "\\end{equation}\n",
        "\n",
        "la matriz identidad es un caso particular de una matriz diagonal, donde todos los elementos no diagonales son 0, lo que se denota como: $D=\\textrm{diag}\\left(d_{1},d_{2},\\ldots,d_{n}\\right)$ con: \n",
        "\n",
        "\\begin{equation}\n",
        "D_{i,j}=\\begin{cases}\n",
        "d_{i} & i=j\\\\\n",
        "0 & i\\neq j\n",
        "\\end{cases}\n",
        "\\end{equation}\n",
        "\n",
        "por lo que entonces $I=\\textrm{diag}\\left(1,1,\\ldots,1\\right)$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Nn3mKl0QRI7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A = torch.tensor([ [1. , 2. , 3. ], [4. , 5. , 6. ] , [7. , 8. , 9.]])\n",
        "print( A )\n",
        "I = torch.eye(3)\n",
        "print( I )\n",
        "D = torch.diag(A)\n",
        "print( D )\n",
        "r = torch.mm( A, I )\n",
        "print( r )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1zgE3UeeHB8S"
      },
      "source": [
        "## La matriz transpuesta\n",
        "\n",
        "La transpuesta de una matriz es el resultado de cambiar las filas a columnas. Sea una matriz $A\\in\\mathbb{R}^{m\\times n}$, su transpuesta se escribe como $A^{T}\\in\\mathbb{R}^{n\\times m}$ y sus entradas están dadas por: \n",
        "\n",
        "\\begin{equation}\n",
        "\\left(A^{T}\\right)_{i,j}=A_{j,i}.\n",
        "\\end{equation}\n",
        "\n",
        "Las siguientes son propiedades de la transpuesta: \n",
        "\n",
        "- $\\left(A^{T}\\right)^{T}=A$\n",
        "- $\\left(AB\\right)^{T}=B^{T}A^{T}$\n",
        "- $\\left(A+B\\right)^{T}=A^{T}+B^{T}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPJTMCiVR5TD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A = torch.tensor([ [1. , 2. , 3. ], [4. , 5. , 6. ] , [7. , 8. , 9.]])\n",
        "print( A )\n",
        "T = torch.t(A)\n",
        "print( T )\n",
        "\n",
        "# otro modo\n",
        "A = torch.tensor([ [1. , 2. , 3. ], [4. , 5. , 6. ] , [7. , 8. , 9.]])\n",
        "T = A.transpose(0, 1)\n",
        "print(T)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-0jY1n2qI0Vj"
      },
      "source": [
        "## Matrices simétricas\n",
        "\n",
        "Una matriz cuadrada $A\\in\\mathbb{R}^{n\\times n}$ es simétrica si $A=A^{T}$ y es anti simétrica si $A=-A^{T}$, Para toda matriz $A\\in\\mathbb{R}^{n\\times n}$ es fácil demostrar que la matriz $A+A^{T}$ es simétrica y la matriz $A-A^{T}$ es anti-simétrica, por lo que se puede seguir que cualquier matriz cuadrada puede expresarse en términos de una matriz simétrica y anti-simétrica:\n",
        "    \n",
        "\\begin{equation}\n",
        "A=\\frac{1}{2}\\left(A+A^{T}\\right)+\\frac{1}{2}\\left(A-A^{T}\\right).\n",
        "\\end{equation}\n",
        "\n",
        "Se define entonces el conjunto de matrices simétricas de dimensiones $n\\times n$ como $\\mathbb{S}^{n}$ por lo que $A\\in\\mathbb{S}^{n}$ si es simétrica. Las matrices simétricas son muy frecuentes en el reconocimiento de patrones, y presentan una serie de propiedades muy útiles que veremos más adelante. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ExfwDU7SoyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A = torch.tensor([ [1. , 2. , 3. ], [2. , 3. , 3. ] , [1. , 2. , 3.]])\n",
        "print( A )\n",
        "T = torch.t(A)\n",
        "print( T )\n",
        "print( torch.equal( A, T))\n",
        "\n",
        "A = torch.tensor([ [1. , 2. , 3. ], [2. , 5. , 0. ] , [3. , 0. , 5.]])\n",
        "print( A )\n",
        "T = torch.t(A)\n",
        "print( T )\n",
        "print( torch.equal( A, T))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JNGuV4yJMdqs"
      },
      "source": [
        "## La traza de una matriz\n",
        "\n",
        "La traza de una matriz cuadrada $A\\in\\mathbb{R}^{n\\times n}$ denotada como $\\textrm{tr}\\left(A\\right)$ es la suma de los elementos en la diagonal de una matriz: \n",
        "\n",
        "\\begin{equation}\n",
        "\\textrm{tr}\\left(A\\right)=\\sum_{i=1}^{n}A_{i,i}\n",
        "\\end{equation}\n",
        "\n",
        "La traza tiene las siguientes propiedades:\n",
        "\n",
        "- $\\textrm{tr}\\left(A\\right)=\\textrm{tr}\\left(A^{T}\\right)$\n",
        "- Superposición $\\textrm{tr}\\left(A+B\\right)=\\textrm{tr}\\left(A\\right)+\\textrm{tr}\\left(B\\right)$\n",
        "- Homogeneidad: Sea $t\\in\\mathbb{R}$, $\\textrm{tr}\\left(t\\,A\\right)=t\\,\\textrm{tr}\\left(A\\right)$\n",
        "- Para $A$ y $B$ cuadradas, se tiene que $\\textrm{tr}\\left(A\\,B\\right)=\\textrm{tr}\\left(B\\,A\\right)$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imqBKV2sUqCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A = torch.tensor([ [1. , 2. , 3. ], [2. , 3. , 3. ] , [1. , 2. , 3.]])\n",
        "print( A )\n",
        "Tr = torch.trace(A)\n",
        "print( Tr )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xGYj-HgVEF0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A = torch.tensor([ [1. , 2. , 3. ], [4. , 5. , 6. ]  ] )\n",
        "B = torch.tensor([ [7. , 8. ], [9. , 1. ] , [2. , 4.] ] )\n",
        "C = torch.mm( A, B)\n",
        "print( C )\n",
        "print( C.shape[0], C.shape[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eJjA74q5PElv"
      },
      "source": [
        "\n",
        "### Producto vector-vector, producto punto\n",
        "\n",
        "Sean dos vectores $\\overrightarrow{x},\\overrightarrow{y}\\in\\mathbb{R}^{n}$ el **producto interno** o producto punto se puede definir, en términos del producto entre tales vectores de la siguiente forma:\n",
        "\n",
        "\\begin{equation}\n",
        "\\overrightarrow{x}\\cdot\\overrightarrow{y}=\\overrightarrow{x}^{T}\\:\\overrightarrow{y}\\in\\mathbb{R}^{1}=\\begin{bmatrix}x_{1} & x_{2} & \\cdots & x_{n}\\end{bmatrix}\\begin{bmatrix}v_{1}\\\\\n",
        "v_{2}\\\\\n",
        "\\vdots\\\\\n",
        "v_{n}\n",
        "\\end{bmatrix}=\\sum_{i=1}^{n}x_{i}\\:y_{i}\n",
        "\\end{equation}\n",
        "\n",
        "Observe entonces que el producto interno es un caso especial de la multiplicación de matrices, y que además, siempre se cumple que: \n",
        "\n",
        "\\begin{equation}\n",
        "\\overrightarrow{x}^{T}\\overrightarrow{y}=\\overrightarrow{y}^{T}\\overrightarrow{x}.\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "\n",
        "### Producto vector-vector o producto externo\n",
        "\n",
        "El **producto externo** en cambio, está dado para dos vectores $\\overrightarrow{x}\\in\\mathbb{R}^{m\\times1}$, $\\overrightarrow{y}\\in\\mathbb{R}^{1\\times n}$ (no necesariamente de la misma dimensionalidad) se define como: \n",
        "\n",
        "\\begin{equation}\n",
        "\\overrightarrow{x} \\odot \\overrightarrow{y}=\\vec{x}\\:\\vec{y}^{T}\\in\\mathbb{R}^{m\\times n}=\\begin{bmatrix}x_{1}\\\\\n",
        "x_{2}\\\\\n",
        "\\vdots\\\\\n",
        "x_{m}\n",
        "\\end{bmatrix}\\begin{bmatrix}y_{1} & y_{2} & \\cdots & y_{n}\\end{bmatrix}=\\begin{bmatrix}x_{1}y_{1} & x_{1}y_{2} & \\cdots & x_{1}y_{n}\\\\\n",
        "x_{2}y_{1} & x_{2}y_{2} & \\cdots & x_{2}y_{n}\\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
        "x_{m}y_{1} & x_{m}y_{2} & \\cdots & x_{m}y_{n}\n",
        "\\end{bmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "El producto externo permite, por ejemplo, crear una matriz $A\\in\\mathbb{R}^{m\\times n}$ cuyas columnas sean igual a un vector $x\\in\\mathbb{R}^{m}$ usando un vector unitario $\\overrightarrow{1}\\in\\mathbb{R}^{n}$, como sigue:\n",
        "\n",
        "\\begin{equation}\n",
        "\\overrightarrow{x}\\,\\overrightarrow{1}^{T}=\\begin{bmatrix}x_{1}\\\\\n",
        "x_{2}\\\\\n",
        "\\vdots\\\\\n",
        "x_{m}\n",
        "\\end{bmatrix}\\begin{bmatrix}1 & 1 & \\cdots & 1\\end{bmatrix}=\\begin{bmatrix}| & | &  & |\\\\\n",
        "\\vec{x} & \\vec{x} & \\cdots & \\vec{x}\\\\\n",
        "| & | &  & |\n",
        "\\end{bmatrix}\n",
        "\\end{equation}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hjr2O6tAV5Dm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# producto interno\n",
        "A = torch.tensor([ 1. , 2.,  3.  ])\n",
        "B = torch.tensor([ 4. , 5. , 6.  ])\n",
        "r = torch.dot( A, B)\n",
        "print( r )\n",
        "\n",
        "# producto externo\n",
        "r = torch.ger( A, torch.t(B) )\n",
        "print( r )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M8KySlYjSCxq"
      },
      "source": [
        "### Producto matriz-vector\n",
        "\n",
        "Sea una matriz $A\\in\\mathbb{R}^{m\\times n}$ y un vector (columna) $\\overrightarrow{x}\\in\\mathbb{R}^{n\\times1}$ su producto es el vector $\\overrightarrow{y}\\in\\mathbb{R}^{m\\times1}$ . \n",
        "\n",
        "Si se escribe a la matriz $A$ por filas, entonces se puede expresar a $A\\,\\overrightarrow{x}$ como: \n",
        "\n",
        "\\begin{equation}\n",
        "\\vec{y}=A\\,\\overrightarrow{x}=\\begin{bmatrix}- & \\vec{a}_{1,:}^{T} & -\\\\\n",
        "- & \\vec{a}_{2,:}^{T} & -\\\\\n",
        " & \\vdots\\\\\n",
        "- & \\vec{a}_{m,:}^{T} & -\n",
        "\\end{bmatrix}\\,\\overrightarrow{x}=\\begin{bmatrix}- & \\vec{a}_{1,:}^{T} & -\\\\\n",
        "- & \\vec{a}_{2,:}^{T} & -\\\\\n",
        " & \\vdots\\\\\n",
        "- & \\vec{a}_{m,:}^{T} & -\n",
        "\\end{bmatrix}\\,\\begin{bmatrix}x_{1}\\\\\n",
        "x_{2}\\\\\n",
        "\\vdots\\\\\n",
        "x_{n}\n",
        "\\end{bmatrix}=\\begin{bmatrix}\\vec{a}_{1,:}^{T}\\:\\vec{x}\\\\\n",
        "\\vec{a}_{2,:}^{T}\\:\\vec{x}\\\\\n",
        "\\vdots\\\\\n",
        "\\vec{a}_{m,:}^{T}\\:\\vec{x}\n",
        "\\end{bmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "En otras palabras, la fila $i$ de $y$ , $y_{i}$ es igual al producto interno de la fila $b_{i}$ con el vector $\\overrightarrow{x}$.\n",
        "\n",
        "Alternativamente, si se escribe la matriz $A$ en forma de columnas, el producto matriz-vector se puede expresar como:\n",
        "\n",
        "\\begin{equation}\n",
        "\\overrightarrow{y}=A\\,\\overrightarrow{x}=\\begin{bmatrix}| & | & \\ldots & |\\\\\n",
        "\\vec{a}_{:,1} & \\vec{a}_{:,2} & \\ldots & \\vec{a}_{:,n}\\\\\n",
        "| & | & \\ldots & |\n",
        "\\end{bmatrix}\\,\\begin{bmatrix}x_{1}\\\\\n",
        "x_{2}\\\\\n",
        "\\vdots\\\\\n",
        "x_{n}\n",
        "\\end{bmatrix}=\\left[\\vec{a}_{:,1}\\right]x_{1}+\\left[\\vec{a}_{:,2}\\right]x_{2}+\\ldots+\\left[\\vec{a}_{:,n}\\right]x_{n}.\n",
        "\\end{equation}\n",
        "\n",
        "ello es fácilmente corroborable si hacemos la multiplicación de sus transpuestas:\n",
        "\n",
        "\\begin{equation}\n",
        "\\overrightarrow{y}^{T}=\\vec{x}^{T}\\,A^{T}=\\begin{bmatrix}x_{1} & x_{2} & \\cdots & x_{n}\\end{bmatrix}\\,\\begin{bmatrix}- & \\vec{a}_{:,1}^{T} & -\\\\\n",
        "- & \\vec{a}_{:,2}^{T} & -\\\\\n",
        " & \\vdots\\\\\n",
        "- & \\vec{a}_{:,n}^{T} & -\n",
        "\\end{bmatrix}=x_{1}\\left[\\vec{a}_{:,1}^{T}\\right]+x_{2}\\left[\\vec{a}_{:,1}^{T}\\right]+\\ldots+x_{n}\\left[\\vec{a}_{:,n}^{T}\\right].\n",
        "\\end{equation}\n",
        "\n",
        "Lo anterior representa el hecho de que el vector $\\overrightarrow{y}$ es una **combinación lineal** de las columnas de la matriz **$A$**, donde los coeficientes están definidos en el vector $\\overrightarrow{x}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb6D2J2Lh4ge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A = torch.tensor([ [1. , 2. , 3. ], [4. , 5. , 6. ] , [7. , 8. , 9.]])\n",
        "x = torch.tensor( [ 2. , 3. , 4.] ) \n",
        "y = torch.mv( A ,  x )\n",
        "print( y )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6qSrLqadhG-N"
      },
      "source": [
        "### Producto matriz-matriz\n",
        "\n",
        "El producto matriz-matriz en general de dos matrices $A\\in\\mathbb{R}^{m\\times n}$ y $B\\in\\mathbb{R}^{n\\times p}$ dado por $C\\in\\mathbb{R}^{m\\times p}$ se puede definir en términos de las filas y columnas, **donde para cada entrada $C_{i,j}$ el producto interno de la fila** $i$ de $A$ y la **columna $j$ de** $B$, simbólicamente esto se expresa como sigue: \n",
        "\n",
        "\\begin{equation}\n",
        "C=A\\,B=\\begin{bmatrix}- & \\vec{a}_{1,:}^{T} & -\\\\\n",
        "- & \\vec{a}_{2,:}^{T} & -\\\\\n",
        " & \\vdots\\\\\n",
        "- & \\vec{a}_{m,:}^{T} & -\n",
        "\\end{bmatrix}\\,\\begin{bmatrix}| & | & \\ldots & |\\\\\n",
        "\\vec{b}_{1,:} & \\vec{b}_{2,:} & \\ldots & \\vec{b}_{p,:}\\\\\n",
        "| & | & \\ldots & |\n",
        "\\end{bmatrix}=\\begin{bmatrix}\\vec{a}_{1,:}^{T}\\vec{b}_{1,:} & \\vec{a}_{1,:}^{T}\\vec{b}_{2,:} & \\cdots & \\vec{a}_{1,:}^{T}\\vec{b}_{p,:}\\\\\n",
        "\\vec{a}_{2,:}^{T}\\vec{b}_{1,:} & \\vec{a}_{2,:}^{T}\\vec{b}_{2,:} & \\cdots & \\vec{a}_{2,:}^{T}\\vec{b}_{p,:}\\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
        "\\vec{a}_{m,:}^{T}\\vec{b}_{1,:} & \\vec{a'}_{m}^{T}\\vec{b}_{2,:} & \\cdots & \\vec{a}_{m,:}^{T}\\vec{b}_{p,:}\n",
        "\\end{bmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "C=A\\,B=\\begin{bmatrix}| & | & \\ldots & |\\\\\n",
        "A\\vec{b}_{1,:} & A\\vec{b}_{2,:} & \\ldots & A\\vec{b}_{p,:}\\\\\n",
        "| & | & \\ldots & |\n",
        "\\end{bmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "La última igualdad representa el hecho de que la columna $j$ de la matriz $C$ es una combinación lineal de los vectores columna de la matriz $A$ con los coeficientes definidos por el vector columna $\\vec{b}_{j,:}$. \n",
        "\n",
        "Las siguientes son propiedades fácilmente corroborables para el producto matricial: \n",
        "\n",
        "- Asociatividad: $\\left(A\\,B\\right)C=A\\left(B\\,C\\right)$.\n",
        "- Distributividad: $A\\left(B+C\\right)=A\\,B+A\\,C$.\n",
        "- No conmutatividad: $A\\,B\\neq B\\,A$.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I7wVURqjSG6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A = torch.tensor([ [1. , 2. , 3. ], [4. , 5. , 6. ]  ] )\n",
        "B = torch.tensor([ [7. , 8. ], [9. , 1. ] , [2. , 4.] ] )\n",
        "C = torch.mm( A, B)\n",
        "print( C )\n",
        "print( C.shape[0], C.shape[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q5BbV17MXCoM"
      },
      "source": [
        "## Independencia lineal y el rango de una matriz\n",
        "\n",
        "Un conjunto de vectores $\\left\\{ \\vec{x}_{1},\\vec{x}_{2},\\ldots,\\vec{x}_{n}\\right\\} \\in\\mathbb{R}^{m}$ se dice que es linealmente independiente, si ningún vector de tal conjunto puede ser representado como una combinación lineal del resto de vectores. De lo contrario, si uno de los vectores en tal conjunto puede ser representado como una combinación lineal del resto de vectores, entonces los vectores son **linealmente dependientes**, lo que se expresa como: \n",
        "\n",
        "\\begin{equation}\n",
        "\\vec{x}_{j}=\\sum_{i=1}^{n-1}\\alpha_{i}\\vec{x}_{i}\n",
        "\\end{equation}\n",
        "\n",
        "para cualquier conjunto de valores escalares $\\alpha_{1},\\ldots,\\alpha_{n-1}\\in\\mathbb{R}$ se dice que el vector $\\vec{x}_{j}\\in\\mathbb{R}^{m}$ es linealmente dependiente de los vectores $\\vec{x}_{i}$. \n",
        "\n",
        "El **rango de columnas** de la matriz $A\\in\\mathbb{R}^{m\\times n}$ corresponde a la cantidad más grande de columnas en la matriz $A$ linealmente independientes, de manera similar, el **rango de filas** se refiere a la cantidad más grande de filas en tal matriz linealmente independientes.\n",
        "\n",
        "Para cualquier matriz $A\\in\\mathbb{R}^{m\\times n}$ se puede comprobar que el rango de filas y el de columnas es el mismo, por lo que entonces la cantidad de filas y columnas linealmente independiente se le refiere con el **rango**:\n",
        "\n",
        "$\\textrm{rango}\\left(A\\right),$con las siguientes propiedades:\n",
        "    \n",
        "- $\\forall A\\in\\mathbb{R}^{m\\times n}$, $\\textrm{rango}\\left(A\\right)\\leq\\min\\left(m,n\\right)$, y si $\\textrm{rango}\\left(A\\right)=\\textrm{min}\\left(m,n\\right)$ se dice que $A$ de **rango completo*.\n",
        "- $\\textrm{rango}\\left(A\\right)\\leq\\textrm{rango}\\left(A^{T}\\right)$\n",
        "- $\\textrm{rango}\\left(A\\,B\\right)\\leq\\min\\left(\\textrm{rango}\\left(A\\right),\\textrm{rango}\\left(B\\right)\\right)$\n",
        "- $\\textrm{rango}\\left(A+B\\right)\\leq\\textrm{rango}\\left(A\\right)+\\textrm{rango}\\left(B\\right)$\n",
        "\n",
        "Ejemplo: \n",
        "\n",
        "Observe la siguiente matriz: \n",
        "\n",
        "\\begin{equation}\n",
        "\\begin{bmatrix}1 & 2 & -1 & 3 & -2\\\\\n",
        "2 & 1 & 0 & 1 & 1\\\\\n",
        "2 & 4 & -2 & 6 & -4\\\\\n",
        "0 & 0 & 0 & 0 & 0\\\\\n",
        "5 & 4 & -1 & 5 & 0\n",
        "\\end{bmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "Fácilmente puede notarse que la fila $f_{3}=2f_{1}$ y además que $f_{5}=2f_{2}+f_{1}$, y que dado que la fila $f_{4}$ es nula, entonces puede ser expresada en términos de cualquier otra fila en una combinación  lineal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZI8menvT39ed",
        "colab": {}
      },
      "source": [
        "rango = torch.matrix_rank( torch.eye(15) )\n",
        "print(\"rango de la matriz \", rango)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yhbMhVqRX3Jp"
      },
      "source": [
        "## La matriz inversa\n",
        "\n",
        "La inversa de la matriz cuadrada $A\\in\\mathbb{R}^{n\\times n}$ se denota como $A^{-1}$ es la única matriz que cumple lo siguiente:\n",
        "\n",
        "\\begin{equation}\n",
        "A^{-1}A=I=A\\,A^{-1}\n",
        "\\end{equation}\n",
        "\n",
        "Nótese que no todas las matrices tienen inversas, por ejemplo las matrices no cuadradas no tienen inversas por definición, e incluso, pueden existir matrices cuadradas sin inversas.\n",
        "\n",
        "- Se dice que $A$ es una matriz **invertible** o no singular si $A^{-1}$ existe, si la matriz $A$ presenta **rango completo**.\n",
        "- Si la matriz $A^{-1}$ no existe, se dice que la matriz es **no invertible** o singular.\n",
        "\n",
        "Las siguientes son las propiedades de la inversa, asumiendo que $A,B\\in\\mathbb{R}^{n\\times n}$ son no-singulares:\n",
        "\n",
        "- $\\left(A^{-1}\\right)^{-1}=A$.\n",
        "- $\\left(A\\,B\\right)^{-1}=B^{-1}A^{-1}$.\n",
        "- $\\left(A^{-1}\\right)^{T}=\\left(A^{T}\\right)^{-1}$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vo_MgPGZmwij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Invertible\n",
        "A = torch.tensor([ [1. , 2. ], [3. , 4. ] ])\n",
        "print( A )\n",
        "Ai = torch.inverse( A ) \n",
        "print( Ai )\n",
        "sorpresa = torch.mm(A, Ai)\n",
        "print( sorpresa )\n",
        "# por capacidad de representación no siempre es cero exacto\n",
        "print( sorpresa.sum())\n",
        "\n",
        "# singular - no invertible\n",
        "A = torch.tensor([ [3. , 2. ], [6. , 4. ] ])\n",
        "print( A )\n",
        "try:\n",
        "  nd = torch.inverse( A )\n",
        "  print(\"Invertible\")\n",
        "except:\n",
        "  print(\"Singular\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oCH95zT-YmfC"
      },
      "source": [
        "## Matrices ortogonales y ortonormales\n",
        "\n",
        "Anteriormente se mencionó que dos vectores $\\vec{x},\\vec{y}\\in\\mathbb{R}^{n}$ son ortogonales si $\\vec{x}^{T}\\vec{y}=0$. Se dice que un vector $\\vec{x}\\in\\mathbb{R}^{n}$ es normalizado si $\\left\\Vert \\vec{x}\\right\\Vert _{2}=1$.\n",
        "\n",
        "Una matriz cuadrada $U\\in\\mathbb{R}^{n\\times n}$ es **ortogonal** si todas las columnas son ortogonales entre ellas. \n",
        "\n",
        "Si además, todos los vectores están normalizados, se dice que la matriz es **ortonormal**.\n",
        "\n",
        "Las siguientes son propiedades de las matrices ortogonales: \n",
        "    \n",
        "- Para toda matriz ortogormal $U\\in\\mathbb{R}^{n\\times n}$ , se cumple que: $U^{T}U=I=U\\,U^{T}$ y sabiendo que $U\\,U^{-1}=I$ se arriba a que $U^{T}=U^{-1}$. Si $U\\in\\mathbb{R}^{m\\times n}$ y $n<m$ pero sus columnas son ortonormales, entonces se cumple que $U^{T}U=I$ pero $U\\,U^{T}\\neq I$.\n",
        "- Para toda matriz ortogonal $U\\in\\mathbb{R}^{n\\times n}$ y vector $\\vec{x}\\in\\mathbb{R}^{n}$, se cumple que el operar el vector con una matriz ortogonal, la norma euclidiana no cambia: \n",
        "\n",
        "\\begin{equation}\n",
        "\\left\\Vert U\\,\\vec{x}\\right\\Vert _{2}=\\left\\Vert \\vec{x}\\right\\Vert _{2}\n",
        "\\end{equation}\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeRvwUe7A03F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ortogonal\n",
        "U = torch.tensor([ [0. , -1.] , [1. , 0. ]])\n",
        "print(\"U \", U )\n",
        "ut = torch.transpose( U, 0, 1)\n",
        "print(\"Ut  \", ut )\n",
        "r = torch.mm( U, ut)\n",
        "print(\" r  \",  r )\n",
        "print(\"I \", torch.eye(2))\n",
        "\n",
        "# ver inversa\n",
        "uinv = torch.inverse(U)\n",
        "print(\"inversa  \", uinv )\n",
        "\n",
        "# ortonormal\n",
        "U = torch.tensor( [ [1., 0., 0.], [0., 1., 0.] , [0., 0., 1.] ] ) \n",
        "ut = torch.transpose( U, 0, 1)\n",
        "r = torch.mm( U, ut)\n",
        "print( r )\n",
        "print(\"normas \")\n",
        "print( torch.norm(U[:,0]))\n",
        "print( torch.norm(U[:,1]))\n",
        "print( torch.norm(U[:,2]))\n",
        "# es ortonormal"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ax5ISHYHJXHj",
        "colab_type": "text"
      },
      "source": [
        "## Pseudo inversa  de una matriz (de Moore-Penrose)\n",
        "\n",
        "\n",
        "La pseudo inversa de Moore-Penrose es una matriz que puede actuar como un reemplazo parcial de la matriz inversa en los casos en que no existe. Esta matriz se usa con frecuencia para resolver un sistema de ecuaciones lineales cuando el sistema no tiene una solución única o tiene muchas soluciones.\n",
        "\n",
        "Para cualquier matriz A, la pseudo inversa B existe, es única y tiene las mismas dimensiones que A. Si A es cuadrada y no singular, entonces pinv (A) es simplemente una forma costosa de calcular inv (A). Sin embargo, si A no es cuadrada, o es cuadrada y singular, entonces inv (A) no existe. \n",
        "\n",
        "\n",
        "La siguiente es una propiedad importante;\n",
        "\n",
        "1. $ \\left(A^{T}A\\right)^{-1}A^{T}\\approx A^{+} $\n",
        "\n",
        "2.  $\\left(A^{T}A\\right)^{+}A^{T}=A^{+}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w73iO8yaJXHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    \n",
        "#pseudo inverse of invertible matrix  \n",
        "print(\"C matrix\")\n",
        "print(C)\n",
        "C = torch.tensor([ [1. , 2. ], [3. , 4. ] , [5. , 6.] ] )\n",
        "try:\n",
        "  C.inverse()\n",
        "  print(\"Éxito en la inversa de C\")\n",
        "except:\n",
        "  print(\"Falló la inversa de C\")\n",
        "Cpinv = C.pinverse()\n",
        "print(\"Pseudo inverted C\", Cpinv)\n",
        "I = C.mm(Cpinv)\n",
        "print(\"C * Cpinv \", I)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}